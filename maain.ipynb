{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set()\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"kidney_disease.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['age', 'blood_pressure', 'specific_gravity', 'albumin', 'sugar', 'red_blood_cells', 'pus_cell',\n",
    "              'pus_cell_clumps', 'bacteria', 'blood_glucose_random', 'blood_urea', 'serum_creatinine', 'sodium',\n",
    "              'potassium', 'haemoglobin', 'packed_cell_volume', 'white_blood_cell_count', 'red_blood_cell_count',\n",
    "              'hypertension', 'diabetes_mellitus', 'coronary_artery_disease', 'appetite', 'peda_edema',\n",
    "              'aanemia', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['packed_cell_volume'] = pd.to_numeric(df['packed_cell_volume'], errors='coerce')\n",
    "df['white_blood_cell_count'] = pd.to_numeric(df['white_blood_cell_count'], errors='coerce')\n",
    "df['red_blood_cell_count'] = pd.to_numeric(df['red_blood_cell_count'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "num_cols = [col for col in df.columns if df[col].dtype != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    print(f\"{col} has {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diabetes_mellitus'].replace(to_replace = {'\\tno':'no', '\\tyes': 'yes', ' yes':'yes'}, inplace=True)\n",
    "df['coronary_artery_disease'] = df['coronary_artery_disease'].replace(to_replace = '\\tno', value = 'no')\n",
    "df['class'] = df['class'].replace(to_replace={'ckd\\t':'ckd', 'notckd': 'not ckd'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['diabetes_mellitus', 'coronary_artery_disease', 'class']\n",
    "for col in cols:\n",
    "    print(f\"{col} has {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['class'].map({'ckd':0, 'not ckd': 1})\n",
    "df['class'] = pd.to_numeric(df['class'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['diabetes_mellitus', 'coronary_artery_disease', 'class']\n",
    "for col in cols:\n",
    "    print(f\"{col} has {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 15))\n",
    "plotnumber = 1\n",
    "\n",
    "for column in num_cols:\n",
    "    if plotnumber <= 14:\n",
    "        ax = plt.subplot(3, 5, plotnumber)\n",
    "        sns.distplot(df[column])\n",
    "        plt.xlabel(column)\n",
    "        \n",
    "    plotnumber += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 15))\n",
    "plotnumber = 1\n",
    "\n",
    "for column in cat_cols:\n",
    "    if plotnumber <= 14:\n",
    "        ax = plt.subplot(3, 5, plotnumber)\n",
    "        sns.countplot(df[column] ,palette = 'rocket')\n",
    "        plt.xlabel(column)\n",
    "        \n",
    "    plotnumber += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "sns.heatmap(df.corr(), annot=True, linewidth=2, linecolor = 'lightgray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voilin(col):\n",
    "    fig  = px.violin(df, y=col, x='class', color='class', box=True, template='plotly_dark')\n",
    "    return fig.show()\n",
    "\n",
    "def kde(col):\n",
    "    grid = sns.FacetGrid(df, hue='class', height = 6, aspect = 2)\n",
    "    grid.map(sns.kdeplot, col)\n",
    "    grid.add_legend()\n",
    "    \n",
    "def scatter_plot(col1, col2):\n",
    "    fig  = px.scatter(df, x=col1, y=col2, color=\"class\",  template='plotly_dark')\n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde('red_blood_cell_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing value\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# two method\n",
    "# radom sampling->higer null value\n",
    "# mean/mode-> lower null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(feature):\n",
    "    random_sample = df[feature].dropna().sample(df[feature].isna().sum())\n",
    "    random_sample.index = df[df[feature].isnull()].index\n",
    "    df.loc[df[feature].isnull(), feature] = random_sample\n",
    "\n",
    "def impute_mode(feature):\n",
    "    mode = df[feature].mode()[0]\n",
    "    df[feature] = df[feature].fillna(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling for numerical value\n",
    "for col in num_cols:\n",
    "    random_sampling(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sampling('red_blood_cells')\n",
    "random_sampling('pus_cell')\n",
    "\n",
    "for col in cat_cols:\n",
    "    impute_mode(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    print(f\"{col} has {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis = 1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test, y_train, y_test =  train_test_split(X,y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn_acc = accuracy_score(y_test, knn.predict(X_test))\n",
    "print(f\"Training Accuracy of KNN is {accuracy_score(y_train, knn.predict(X_train))}\")\n",
    "print(f\"Testing Accuracy of KNN is {accuracy_score(y_test, knn.predict(X_test))}\")\n",
    "\n",
    "print(f\"Confusion Matrix of KNN is \\n {confusion_matrix(y_test, knn.predict(X_test))}\\n\")\n",
    "print(f\"Classification Report of KNN is \\n{classification_report(y_test, knn.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_acc = accuracy_score(y_test, dtc.predict(X_test))\n",
    "print(f\"Training Accuracy of DTC is {accuracy_score(y_train, dtc.predict(X_train))}\")\n",
    "print(f\"Testing Accuracy of DTC is {accuracy_score(y_test, dtc.predict(X_test))}\")\n",
    "\n",
    "print(f\"Confusion Matrix of DTC is \\n {confusion_matrix(y_test, dtc.predict(X_test))}\\n\")\n",
    "print(f\"Classification Report of DTC is \\n{classification_report(y_test, dtc.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "GRID_PARAMETER = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[3,5,7,10],\n",
    "    'splitter':['best','random'],\n",
    "    'min_samples_leaf':[1,2,3,5,7],\n",
    "    'min_samples_split':[1,2,3,5,7],\n",
    "    'max_features':['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search_dtc = GridSearchCV(dtc, GRID_PARAMETER, cv=5, n_jobs=-1, verbose = 1)\n",
    "grid_search_dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best paramer and best score\n",
    "print(grid_search_dtc.best_params_)\n",
    "print(grid_search_dtc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = grid_search_dtc.best_estimator_\n",
    "\n",
    "dtc_acc = accuracy_score(y_test, dtc.predict(X_test))\n",
    "print(f\"Training Accuracy of DTC is {accuracy_score(y_train, dtc.predict(X_train))}\")\n",
    "print(f\"Testing Accuracy of DTC is {accuracy_score(y_test, dtc.predict(X_test))}\")\n",
    "\n",
    "print(f\"Confusion Matrix of DTC is \\n {confusion_matrix(y_test, dtc.predict(X_test))}\\n\")\n",
    "print(f\"Classification Report of DTC is \\n{classification_report(y_test, dtc.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rand_clf = RandomForestClassifier(criterion = \"gini\", max_depth = 10, max_features=\"sqrt\", min_samples_leaf= 1, min_samples_split= 7, n_estimators = 400)\n",
    "rand_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_clf_acc = accuracy_score(y_test, rand_clf.predict(X_test))\n",
    "print(f\"Training Accuracy of Random Forest is {accuracy_score(y_train, rand_clf.predict(X_train))}\")\n",
    "print(f\"Testing Accuracy of Random Forest is {accuracy_score(y_test, rand_clf.predict(X_test))}\")\n",
    "\n",
    "print(f\"Confusion Matrix of Random Forest is \\n {confusion_matrix(y_test, rand_clf.predict(X_test))}\\n\")\n",
    "print(f\"Classification Report of Random Forest is \\n{classification_report(y_test, rand_clf.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XgBoost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(objective=\"binary:logistic\", learning_rate = 0.001, max_depth = 10, n_estimators = 100)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_acc = accuracy_score(y_test, xgb.predict(X_test))\n",
    "print(f\"Training Accuracy of XGB is {accuracy_score(y_train, xgb.predict(X_train))}\")\n",
    "print(f\"Testing Accuracy of XGB is {accuracy_score(y_test, xgb.predict(X_test))}\")\n",
    "\n",
    "print(f\"Confusion Matrix of XGB is \\n {confusion_matrix(y_test, xgb.predict(X_test))}\\n\")\n",
    "print(f\"Classification Report of XGB is \\n{classification_report(y_test, xgb.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_acc = accuracy_score(y_test, lr.predict(X_test))\n",
    "print(f\"Training Accuracy of LR is {accuracy_score(y_train, lr.predict(X_train))}\")\n",
    "print(f\"Testing Accuracy of LR is {accuracy_score(y_test, lr.predict(X_test))}\")\n",
    "\n",
    "print(f\"Confusion Matrix of LR is \\n {confusion_matrix(y_test, lr.predict(X_test))}\\n\")\n",
    "print(f\"Classification Report of LR is \\n{classification_report(y_test, lr.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm  = SVC(probability=True)\n",
    "\n",
    "parameter = {\n",
    "    'gamma':[0.0001, 0.001, 0.01, 0.1],\n",
    "    'C':[0.01, 0.05, 0.5, 0.1, 1, 10, 15, 20]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(svm, parameter)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 15, 'gamma': 0.0001}\n",
      "0.765625\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm  = SVC(gamma = 0.0001, C  = 15, probability=True)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_acc = accuracy_score(y_test, svm.predict(X_test))\n",
    "print(f\"Training Accuracy of SVC is {accuracy_score(y_train, svm.predict(X_train))}\")\n",
    "print(f\"Testing Accuracy of SVC is {accuracy_score(y_test, svm.predict(X_test))}\")\n",
    "\n",
    "print(f\"Confusion Matrix of SVC is \\n {confusion_matrix(y_test, svm.predict(X_test))}\\n\")\n",
    "print(f\"Classification Report of SVC is \\n{classification_report(y_test, svm.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "PARAMETERS = {\n",
    "    'loss': ['log_loss', 'exponential'],\n",
    "    'learning_rate':[0.001, 0.1, 1, 10],\n",
    "    'n_estimators':[100,150,180, 200]\n",
    "}\n",
    "grid_search_gbc = GridSearchCV(gbc, PARAMETERS, cv=5, n_jobs=-1, verbose= 1)\n",
    "grid_search_gbc.fit(X_train, y_train)\n",
    "print(grid_search_gbc.best_params_)\n",
    "print(grid_search_gbc.best_score_)\n",
    "gbc = GradientBoostingClassifier(learning_rate= 0.1, loss = 'log_loss', n_estimators = 100)\n",
    "gbc.fit(X_train, y_train)\n",
    "gbc_acc = accuracy_score(y_test, gbc.predict(X_test))\n",
    "print(f\"Training Accuracy of GBC is {accuracy_score(y_train, gbc.predict(X_train))}\")\n",
    "print(f\"Testing Accuracy of GBC is {accuracy_score(y_test, gbc.predict(X_test))}\")\n",
    "\n",
    "print(f\"Confusion Matrix of GBC is \\n {confusion_matrix(y_test, gbc.predict(X_test))}\\n\")\n",
    "print(f\"Classification Report of GBC is \\n{classification_report(y_test, gbc.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search_gbc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(learning_rate= 0.1, loss = 'log_loss', n_estimators = 100)\n",
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_acc = accuracy_score(y_test, gbc.predict(X_test))\n",
    "print(f\"Training Accuracy of GBC is {accuracy_score(y_train, gbc.predict(X_train))}\")\n",
    "print(f\"Testing Accuracy of GBC is {accuracy_score(y_test, gbc.predict(X_test))}\")\n",
    "\n",
    "print(f\"Confusion Matrix of GBC is \\n {confusion_matrix(y_test, gbc.predict(X_test))}\\n\")\n",
    "print(f\"Classification Report of GBC is \\n{classification_report(y_test, gbc.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison\n",
    "\n",
    "models = pd.DataFrame({\n",
    "    'Model':['Logistic Regression', 'KNN', 'SVM', 'DT', 'Random Forest Classifier', 'XgBoost','Gradient Boosting'],\n",
    "    'Score':[lr_acc, knn_acc, svm_acc, dtc_acc, rand_clf_acc, xgb_acc, gbc_acc]\n",
    "})\n",
    "\n",
    "models.sort_values(by='Score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = dtc\n",
    "pickle.dump(model, open(\"kindey.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "plt.figure(figsize=(8,5))\n",
    "models = [\n",
    "{\n",
    "    'label': 'LR',\n",
    "    'model': lr,\n",
    "},\n",
    "{\n",
    "    'label': 'DT',\n",
    "    'model': dtc,\n",
    "},\n",
    "{\n",
    "    'label': 'SVM',\n",
    "    'model': svm,\n",
    "},\n",
    "{\n",
    "    'label': 'KNN',\n",
    "    'model': knn,\n",
    "},\n",
    "{\n",
    "    'label': 'XGBoost',\n",
    "    'model': xgb,\n",
    "},\n",
    "{\n",
    "    'label': 'RF',\n",
    "    'model': rand_clf,\n",
    "},\n",
    "{\n",
    "    'label': 'GBDT',\n",
    "    'model': gbc,\n",
    "}\n",
    "]\n",
    "for m in models:\n",
    "    model = m['model'] \n",
    "    model.fit(X_train, y_train) \n",
    "    y_pred=model.predict(X_test) \n",
    "    fpr1, tpr1, thresholds = metrics.roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "    auc = metrics.roc_auc_score(y_test,model.predict(X_test))\n",
    "    plt.plot(fpr1, tpr1, label='%s - ROC (area = %0.2f)' % (m['label'], auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity (False Positive Rate)', fontsize=12)\n",
    "plt.ylabel('Sensitivity (True Positive Rate)', fontsize=12)\n",
    "plt.title('ROC - Kidney Disease Prediction', fontsize=12)\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.savefig(\"roc_kidney.jpeg\", format='jpeg', dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "models = [\n",
    "{\n",
    "    'label': 'LR',\n",
    "    'model': lr,\n",
    "},\n",
    "{\n",
    "    'label': 'DT',\n",
    "    'model': dtc,\n",
    "},\n",
    "{\n",
    "    'label': 'SVM',\n",
    "    'model': svm,\n",
    "},\n",
    "{\n",
    "    'label': 'KNN',\n",
    "    'model': knn,\n",
    "},\n",
    "{\n",
    "    'label': 'XGBoost',\n",
    "    'model': xgb,\n",
    "},\n",
    "{\n",
    "    'label': 'RF',\n",
    "    'model': rand_clf,\n",
    "},\n",
    "{\n",
    "    'label': 'GBDT',\n",
    "    'model': gbc,\n",
    "}\n",
    "]\n",
    "\n",
    "means_roc = []\n",
    "means_accuracy = [100*round(lr_acc,4), 100*round(dtc_acc,4), 100*round(svm_acc,4), 100*round(knn_acc,4), 100*round(xgb_acc,4), \n",
    "                  100*round(rand_clf_acc,4), 100*round(gbc_acc,4)]\n",
    "\n",
    "for m in models:\n",
    "    model = m['model'] \n",
    "    model.fit(X_train, y_train) \n",
    "    y_pred=model.predict(X_test) \n",
    "    fpr1, tpr1, thresholds = metrics.roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "    auc = metrics.roc_auc_score(y_test,model.predict(X_test))\n",
    "    auc = 100*round(auc,4)\n",
    "    means_roc.append(auc)\n",
    "\n",
    "print(means_accuracy)\n",
    "print(means_roc)\n",
    "\n",
    "\n",
    "n_groups = 7\n",
    "means_accuracy = tuple(means_accuracy)\n",
    "means_roc = tuple(means_roc)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, means_accuracy, bar_width,\n",
    "alpha=opacity,\n",
    "color='mediumpurple',\n",
    "label='Accuracy (%)')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, means_roc, bar_width,\n",
    "alpha=opacity,\n",
    "color='rebeccapurple',\n",
    "label='ROC (%)')\n",
    "\n",
    "plt.xlim([-1, 8])\n",
    "plt.ylim([45, 104])\n",
    "\n",
    "plt.title('Performance Evaluation - Kidney Disease Prediction', fontsize=12)\n",
    "plt.xticks(index, ('   LR', '   DT', '   SVM', '   KNN', 'XGBoost' , '   RF', '   GBDT'), rotation=40, ha='center', fontsize=12)\n",
    "plt.legend(loc=\"upper right\", fontsize=10)\n",
    "plt.savefig(\"PE_kidney.jpeg\", format='jpeg', dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
